{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: The resource group doesn't exist or was not provided. AzureML SDK is creating a resource group=rgAMLSLearnworkspace in location=northeurope using subscription=87531c67-f272-45f2-a6fe-c13b28bc4f46.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying KeyVault with name testworkkeyvaultaf8b3035.\n",
      "Deploying StorageAccount with name testworkstoragee9b5d22c3.\n",
      "Deploying AppInsights with name testworkinsightse16dc19e.\n",
      "Deployed AppInsights with name testworkinsightse16dc19e. Took 7.57 seconds.\n",
      "Deployed KeyVault with name testworkkeyvaultaf8b3035. Took 18.62 seconds.\n",
      "Deployed StorageAccount with name testworkstoragee9b5d22c3. Took 24.98 seconds.\n",
      "Deploying Workspace with name testworkspace.\n",
      "Deployed Workspace with name testworkspace. Took 23.52 seconds.\n",
      "AMLS Workspace created\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------\n",
    "# Create a workspace\n",
    "#---------------------------------------\n",
    "import azureml.core\n",
    "\n",
    "print(azureml.core.VERSION)\n",
    "\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.create(name='testworkspace',\n",
    "            subscription_id='87531c67-f272-45f2-a6fe-c13b28bc4f46', \n",
    "            resource_group='rgAMLSLearnworkspace',\n",
    "            create_resource_group = True,\n",
    "            location='North Europe'\n",
    "            )\n",
    "\n",
    "print('AMLS Workspace created')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute target created\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------\n",
    "# (1) Create a remote compute target\n",
    "#---------------------------------------\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# Step 1: name the cluster and set the minimal and maximal number of nodes \n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpucluster\")\n",
    "min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 3)\n",
    "\n",
    "# Step 2: choose environment variables \n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "provisioning_config = AmlCompute.provisioning_configuration(\n",
    "    vm_size = vm_size, min_nodes = min_nodes, max_nodes = max_nodes)\n",
    "\n",
    "# create the cluster\n",
    "compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "\n",
    "print('Compute target created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------\n",
    "# (2) Retrieve the MNIST data\n",
    "#---------------------------------------\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "#create a folder for the dataset\n",
    "os.makedirs('./data', exist_ok = True)\n",
    "\n",
    "# load dataset to the directory--as you can see, you must load train sets and test sets separately\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', filename='./data/train-images.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', filename='./data/train-labels.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', filename='./data/test-images.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', filename='./data/test-labels.gz')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorResponseException",
     "evalue": "Operation returned an invalid status code 'Forbidden'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mErrorResponseException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-51b95dafc256>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#-----------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#upload data by using get_default_datastore()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_datastore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mnist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Junction-2019-fvZjpDfB/lib/python3.6/site-packages/azureml/core/workspace.py\u001b[0m in \u001b[0;36mget_default_datastore\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatastore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatastore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \"\"\"\n\u001b[0;32m--> 783\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_DatastoreClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_default_datastore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Junction-2019-fvZjpDfB/lib/python3.6/site-packages/azureml/data/datastore_client.py\u001b[0m in \u001b[0;36mget_default\u001b[0;34m(workspace)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAzureFileDatastore\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mAzureBlobDatastore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \"\"\"\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_DatastoreClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Junction-2019-fvZjpDfB/lib/python3.6/site-packages/azureml/data/datastore_client.py\u001b[0m in \u001b[0;36m_get_default\u001b[0;34m(ws, auth, host)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_DatastoreClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         ds = client.data_stores.get_default(ws._subscription_id, ws._resource_group, ws._workspace_name,\n\u001b[0;32m--> 689\u001b[0;31m                                             custom_headers=_DatastoreClient._custom_headers)\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_DatastoreClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dto_to_datastore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Junction-2019-fvZjpDfB/lib/python3.6/site-packages/azureml/_restclient/operations/data_stores_operations.py\u001b[0m in \u001b[0;36mget_default\u001b[0;34m(self, subscription_id, resource_group_name, workspace_name, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mErrorResponseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mdeserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mErrorResponseException\u001b[0m: Operation returned an invalid status code 'Forbidden'"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------\n",
    "# (3) Load data and create a modeling script\n",
    "#-----------------------------------------\n",
    "#upload data by using get_default_datastore()\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(src_dir='./data', target_path='mnist', overwrite=True, show_progress=True)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# create the folder\n",
    "folder_training_script = './trial_model_mnist'\n",
    "os.makedirs(folder_training_script, exist_ok=True)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $folder_training_script/train.py\n",
    "\n",
    "# Let's prepare our model training script\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from azureml.core import Run\n",
    "# from utils import load_data\n",
    "\n",
    "import gzip\n",
    "import struct\n",
    "\n",
    "# load compressed MNIST gz files and return numpy arrays\n",
    "def load_data(filename, label=False):\n",
    "    with gzip.open(filename) as gz:\n",
    "        struct.unpack('I', gz.read(4))\n",
    "        n_items = struct.unpack('>I', gz.read(4))\n",
    "        if not label:\n",
    "            n_rows = struct.unpack('>I', gz.read(4))[0]\n",
    "            n_cols = struct.unpack('>I', gz.read(4))[0]\n",
    "            res = np.frombuffer(gz.read(n_items[0] * n_rows * n_cols), dtype=np.uint8)\n",
    "            res = res.reshape(n_items[0], n_rows * n_cols)\n",
    "        else:\n",
    "            res = np.frombuffer(gz.read(n_items[0]), dtype=np.uint8)\n",
    "            res = res.reshape(n_items[0], 1)\n",
    "    return res\n",
    "\n",
    "\n",
    "# let user feed in 2 parameters, the dataset to mount or download, and the regularization rate of the logistic regression model\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "parser.add_argument('--regularization', type=float, dest='reg', default=0.01, help='regularization rate')\n",
    "args = parser.parse_args()\n",
    "\n",
    "###\n",
    "data_folder = os.path.join(args.data_folder, 'mnist')\n",
    "print('Data folder:', data_folder)\n",
    "\n",
    "# load the train and test set into numpy arrays\n",
    "X_train = load_data(os.path.join(data_folder, 'train-images.gz'), False) / 255.0\n",
    "X_test = load_data(os.path.join(data_folder, 'test-images.gz'), False) / 255.0\n",
    "\n",
    "#print variable set dimension\n",
    "print(X_train.shape, X_test.shape, sep = '\\n')\n",
    "\n",
    "y_train = load_data(os.path.join(data_folder, 'train-labels.gz'), True).reshape(-1)\n",
    "y_test = load_data(os.path.join(data_folder, 'test-labels.gz'), True).reshape(-1)\n",
    "\n",
    "#print the response variable dimension\n",
    "print( y_train.shape, y_test.shape, sep = '\\n')\n",
    "\n",
    "# get hold of the current run\n",
    "run = Run.get_context()\n",
    "\n",
    "print('Train a logistic regression model with regularization rate of', args.reg)\n",
    "clf = LogisticRegression(C=1.0/args.reg, solver=\"liblinear\", multi_class=\"auto\", random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Predict the test set')\n",
    "y_hat = clf.predict(X_test)\n",
    "\n",
    "# calculate accuracy on the prediction\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy is', acc)\n",
    "\n",
    "run.log('regularization rate', np.float(args.reg))\n",
    "run.log('accuracy', np.float(acc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=clf, filename='outputs/sklearn_mnist_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.as_mount(),\n",
    "    '--regularization': 0.5\n",
    "}\n",
    "\n",
    "#import the Scikit-learn package \n",
    "est = SKLearn(source_directory=folder_training_script,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                entry_script='train.py',\n",
    "                conda_packages=['scikit-learn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------\n",
    "# (4) Submit the model, monitor the run, and retrieve the results\n",
    "#-----------------------------------------------------------------\n",
    "from azureml.core import Experiment\n",
    "\n",
    "#Create an experiment\n",
    "experiment = Experiment(workspace = ws, name = \"amls-learn-experimentnew5\")\n",
    "\n",
    "print('Experiment created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.submit(config=est)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
